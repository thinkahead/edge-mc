<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>KCP-Edge â€“ Milestone PoC2023q1</title><link>https://docs.kcp-edge.io/docs/coding-milestones/poc2023q1/</link><description>Recent content in Milestone PoC2023q1 on KCP-Edge</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://docs.kcp-edge.io/docs/coding-milestones/poc2023q1/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Details</title><link>https://docs.kcp-edge.io/docs/coding-milestones/poc2023q1/outline/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.kcp-edge.io/docs/coding-milestones/poc2023q1/outline/</guid><description>
&lt;div class="pageinfo pageinfo-primary">
&lt;p>Status of this memo: This summarizes the current state of design work that is still in
progress.&lt;/p>
&lt;/div>
&lt;img alt="poc2023q1 architecture" align="center" src="https://docs.kcp-edge.io/docs/coding-milestones/poc2023q1/Edge-PoC-2023q1.svg" />
&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>This is a quick demo of a fragment of what we think is needed for edge
multi-cluster. It is intended to demonstrate the following points.&lt;/p>
&lt;ul>
&lt;li>Separation of inventory and workload management.&lt;/li>
&lt;li>The focus here is on workload management, and that strictly reads
inventory.&lt;/li>
&lt;li>What passes from inventory to workload management is kcp TMC
Location and SyncTarget objects.&lt;/li>
&lt;li>Use of a kcp workspace as the container for the central spec of a workload.&lt;/li>
&lt;li>Propagation of desired state from center to edge, as directed by
EdgePlacement objects and the Location and SyncTarget objects they reference.&lt;/li>
&lt;li>Interfaces designed for a large number of edge clusters.&lt;/li>
&lt;li>Interfaces designed with the intention that edge clusters operate
independently of each other and the center (e.g., can tolerate only
occasional connectivity) and thus any &amp;ldquo;service providers&amp;rdquo; (in the
technical sense from kcp) in the center or elsewhere.&lt;/li>
&lt;li>Rule-based customization of desired state.&lt;/li>
&lt;li>Propagation of reported state from edge to center.&lt;/li>
&lt;li>Summarization of reported state in the center.&lt;/li>
&lt;li>The edge opens connections to the center, not vice-versa.&lt;/li>
&lt;li>An edge computing platform &amp;ldquo;product&amp;rdquo; that can be deployed (as
opposed to a service that is used).&lt;/li>
&lt;/ul>
&lt;p>Some important things that are not attempted in this PoC include the following.&lt;/p>
&lt;ul>
&lt;li>An implementation that supports a large number of edge clusters or
any other thing that requires sharding for scale.&lt;/li>
&lt;li>More than one SyncTarget per Location.&lt;/li>
&lt;li>Return or summarization of reported state from associated objects
(e.g., ReplicaSet or Pod objects associated with a given Deployment
object).&lt;/li>
&lt;li>A hierarchy with more than two levels.&lt;/li>
&lt;li>User control over ordering of propagation from center to edge,
either among destinations or kinds of objects.&lt;/li>
&lt;li>More than baseline security (baseline being, e.g., HTTPS, Secret
objects, non-rotating bearer token based service authentication).&lt;/li>
&lt;li>A good design for bootstrapping the workload management in the edge
clusters.&lt;/li>
&lt;li>Support for workload object types that are not either built into kcp
or imported via a kcp APIBinding.&lt;/li>
&lt;li>Very strong isolation between tenants in the edge computing
platform.&lt;/li>
&lt;/ul>
&lt;p>It is TBD whether the implementation will support intermittent
connectivity. This depends on whether we can quickly and easily get a
syncer that creates the appropriately independent objects in the edge
cluster and itself tolerates intermittent connectivity.&lt;/p>
&lt;p>As further matters of roadmapping development of this PoC:
customization may be omitted at first, and summarization may start
with only a limited subset of the implicit functionality.&lt;/p>
&lt;p>This PoC builds on TMC and makes some compromises to accommodate that.
The implementation involves workload components (syncers) writing
status information to inventory objects (SyncTargets).&lt;/p>
&lt;h2 id="roles-and-responsibilities">Roles and Responsibilities&lt;/h2>
&lt;ul>
&lt;li>Developers/deployers/admins/users of the inventory management layer&lt;/li>
&lt;li>Developers of the workload management layer&lt;/li>
&lt;li>Deployers/admins of the workload management layer&lt;/li>
&lt;li>Users of the workload management layer&lt;/li>
&lt;/ul>
&lt;h2 id="design-overview">Design overview&lt;/h2>
&lt;p>In very brief: the design is to reduce each edge placement problem to
many instances of kcp&amp;rsquo;s TMC problem.&lt;/p>
&lt;p>See &lt;a href="Edge-PoC-2023q1.svg">the overview picture&lt;/a> for an overview
picture.&lt;/p>
&lt;h2 id="inventory-management-workspaces">Inventory Management workspaces&lt;/h2>
&lt;p>This design takes as a given that something maintains some kcp
workspaces that contain dynamic collections of Location and SyncTarget
objects as defined in &lt;a href="https://github.com/kcp-dev/kcp/tree/main/pkg/apis">kcp
TMC&lt;/a>, and that one
view can be used to read those Location objects and one view can be
used to read those SyncTarget objects.&lt;/p>
&lt;p>To complete the plumbing of the syncers, each inventory workspace that
contains a SyncTarget needs to also contain the following associated
objects. FYI, these are the things that &lt;code>kubectl kcp workload sync&lt;/code>
directly creates besides the SyncTarget. Ensuring their presence is
part of the problem of bootstrapping the workload management layer and
is not among the things that this PoC takes a position on.&lt;/p>
&lt;ol>
&lt;li>A ServiceAccount that the syncer will authenticate as.&lt;/li>
&lt;li>A ClusterRole manipulating that SyncTarget and the
APIResourceImports (what are these?).&lt;/li>
&lt;li>A ClusterRoleBinding that links that ServiceAccount with that
ClusterRole.&lt;/li>
&lt;/ol>
&lt;h2 id="edge-service-provider-workspace">Edge Service Provider workspace&lt;/h2>
&lt;p>The edge multi-cluster service is provided by one workspace that
includes the following things.&lt;/p>
&lt;ul>
&lt;li>An APIExport of the edge API group.&lt;/li>
&lt;li>The edge controllers: scheduler, placement translator, mailbox
controller, and status sumarizer.&lt;/li>
&lt;/ul>
&lt;h2 id="workload-management-workspaces">Workload Management workspaces&lt;/h2>
&lt;p>The users of edge multi-cluster primarily maintain these. Each one of
these has both control (API objects that direct the behavior of the
edge computing platform) and data (API objects that hold workload
desired and reported state).&lt;/p>
&lt;h3 id="data-objects">Data objects&lt;/h3>
&lt;p>The workload desired state is represented by kube-style API objects,
in the way that is usual in the Kubernetes milieu. For edge computing
we need to support both cluster-scoped (AKA non-namespaced) kinds as
well as namespaced kinds of objects.&lt;/p>
&lt;p>The use of a workspace as a mere container presents a challenge,
because some kinds of kubernetes API objects at not merely data but
also modify the behavior of the apiserver holding them. To resolve
this dilemma, the edge users of such a workspace will use a special
view of the workspace that holds only data objects. The ones that
modify apiserver behavior will be translated by the view into
&amp;ldquo;denatured&amp;rdquo; versions of those objects in the actual workspace so that
they have no effect on it. And for these objects, the transport from
center-to-edge will do the inverse: translate the denatured versions
into the regular (&amp;ldquo;natured&amp;rdquo;?) versions for appearance in the edge
cluster. Furthermore, for some kinds of objects that modify apiserver
behavior we want them &amp;ldquo;natured&amp;rdquo; at both center and edge. There are
thus a few categories of kinds of objects. Following is a listing,
with with the particular kinds that appear in kcp or plain kubernetes.&lt;/p>
&lt;h4 id="needs-to-be-denatured-in-center-natured-in-edge">Needs to be denatured in center, natured in edge&lt;/h4>
&lt;p>For these kinds of objects, clients of the real workspace can
manipulate such objects and they will modify the behavior of the
workspace, while clients of the edge computing view will manipulate
distinct objects that have no effect on the behavior of the workspace.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>APIVERSION&lt;/th>
&lt;th>KIND&lt;/th>
&lt;th>NAMESPACED&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>admissionregistration.k8s.io/v1&lt;/td>
&lt;td>MutatingWebhookConfiguration&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>admissionregistration.k8s.io/v1&lt;/td>
&lt;td>ValidatingWebhookConfiguration&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>flowcontrol.apiserver.k8s.io/v1beta2&lt;/td>
&lt;td>FlowSchema&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>flowcontrol.apiserver.k8s.io/v1beta2&lt;/td>
&lt;td>PriorityLevelConfiguration&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>rbac.authorization.k8s.io/v1&lt;/td>
&lt;td>ClusterRole&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>rbac.authorization.k8s.io/v1&lt;/td>
&lt;td>ClusterRoleBinding&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>rbac.authorization.k8s.io/v1&lt;/td>
&lt;td>Role&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>rbac.authorization.k8s.io/v1&lt;/td>
&lt;td>RoleBinding&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>LimitRange&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>ResourceQuota&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>ServiceAccount&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h4 id="needs-to-be-natured-in-center-and-edge">Needs to be natured in center and edge&lt;/h4>
&lt;p>These should have their usual effect in both center and edge; they
need no distinct treatment.&lt;/p>
&lt;p>Note, however, that they &lt;em>do&lt;/em> have some sequencing implications. They
have to be created before any dependent objects, deleted after all
dependent objects.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>APIVERSION&lt;/th>
&lt;th>KIND&lt;/th>
&lt;th>NAMESPACED&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>apiextensions.k8s.io/v1&lt;/td>
&lt;td>CustomResourceDefinition&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>Namespace&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="needs-to-be-natured-in-center-not-destined-for-edge">Needs to be natured in center, not destined for edge&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>APIVERSION&lt;/th>
&lt;th>KIND&lt;/th>
&lt;th>NAMESPACED&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>apis.kcp.io/v1alpha1&lt;/td>
&lt;td>APIBinding&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>A workload management workspace generally has APIBindings to workload
APIs. These bindings cause corresponding CRDs to be created in the
same workspace. The CRDs propagate to the edge, the APIBindings do
not.&lt;/p>
&lt;h4 id="for-features-not-supported">For features not supported&lt;/h4>
&lt;p>These are part of k8s or kcp APIs that are not supported by the edge
computing platform.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>APIVERSION&lt;/th>
&lt;th>KIND&lt;/th>
&lt;th>NAMESPACED&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>apiregistration.k8s.io/v1&lt;/td>
&lt;td>APIService&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>apiresource.kcp.io/v1alpha1&lt;/td>
&lt;td>APIResourceImport&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>apiresource.kcp.io/v1alpha1&lt;/td>
&lt;td>NegotiatedAPIResource&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>apis.kcp.io/v1alpha1&lt;/td>
&lt;td>APIConversion&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>The APIService objects are of two sorts: (a) those that are built-in
and describe object types built into the apiserver and (b) those that
are added by admins to add API groups served by custom external
servers. Sort (b) is not supported because this PoC does not support
custom external servers in the edge clusters. Sort (a) is not
programmable in this PoC, but it might be inspectable.&lt;/p>
&lt;h4 id="not-destined-for-edge">Not destined for edge&lt;/h4>
&lt;p>These kinds of objects are concerned with either (a) TMC control or
(b) workload data that should only exist in the edge clusters. These
will not be available in the view used by edge clients to maintain
their workload desired and reported state.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>APIVERSION&lt;/th>
&lt;th>KIND&lt;/th>
&lt;th>NAMESPACED&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>apis.kcp.io/v1alpha1&lt;/td>
&lt;td>APIExport&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>apis.kcp.io/v1alpha1&lt;/td>
&lt;td>APIExportEndpointSlice&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>apis.kcp.io/v1alpha1&lt;/td>
&lt;td>APIResourceSchema&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>apps/v1&lt;/td>
&lt;td>ControllerRevision&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>authentication.k8s.io/v1&lt;/td>
&lt;td>TokenReview&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>authorization.k8s.io/v1&lt;/td>
&lt;td>LocalSubjectAccessReview&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>authorization.k8s.io/v1&lt;/td>
&lt;td>SelfSubjectAccessReview&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>authorization.k8s.io/v1&lt;/td>
&lt;td>SelfSubjectRulesReview&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>authorization.k8s.io/v1&lt;/td>
&lt;td>SubjectAccessReview&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>certificates.k8s.io/v1&lt;/td>
&lt;td>CertificateSigningRequest&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>coordination.k8s.io/v1&lt;/td>
&lt;td>Lease&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>core.kcp.io/v1alpha1&lt;/td>
&lt;td>LogicalCluster&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>core.kcp.io/v1alpha1&lt;/td>
&lt;td>Shard&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>events.k8s.io/v1&lt;/td>
&lt;td>Event&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>scheduling.kcp.io/v1alpha1&lt;/td>
&lt;td>Location&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>scheduling.kcp.io/v1alpha1&lt;/td>
&lt;td>Placement&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>tenancy.kcp.io/v1alpha1&lt;/td>
&lt;td>ClusterWorkspace&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>tenancy.kcp.io/v1alpha1&lt;/td>
&lt;td>Workspace&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>tenancy.kcp.io/v1alpha1&lt;/td>
&lt;td>WorkspaceType&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>topology.kcp.io/v1alpha1&lt;/td>
&lt;td>Partition&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>topology.kcp.io/v1alpha1&lt;/td>
&lt;td>PartitionSet&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>Binding&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>ComponentStatus&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>Event&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>Node&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>workload.kcp.io/v1alpha1&lt;/td>
&lt;td>SyncTarget&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h4 id="already-denatured-in-center-want-natured-in-edge">Already denatured in center, want natured in edge&lt;/h4>
&lt;p>These are kinds of objects that kcp already gives no interpretation
to.&lt;/p>
&lt;p>This is the default category of kind of object &amp;mdash; any kind of data
object not specifically listed in another category is implicitly in
this category. Following are the kinds from k8s and kcp that fall in
this category.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>APIVERSION&lt;/th>
&lt;th>KIND&lt;/th>
&lt;th>NAMESPACED&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>apps/v1&lt;/td>
&lt;td>DaemonSet&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>apps/v1&lt;/td>
&lt;td>Deployment&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>apps/v1&lt;/td>
&lt;td>ReplicaSet&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>apps/v1&lt;/td>
&lt;td>StatefulSet&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>autoscaling/v2&lt;/td>
&lt;td>HorizontalPodAutoscaler&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>batch/v1&lt;/td>
&lt;td>CronJob&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>batch/v1&lt;/td>
&lt;td>Job&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>networking.k8s.io/v1&lt;/td>
&lt;td>Ingress&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>networking.k8s.io/v1&lt;/td>
&lt;td>IngressClass&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>networking.k8s.io/v1&lt;/td>
&lt;td>NetworkPolicy&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>node.k8s.io/v1&lt;/td>
&lt;td>RuntimeClass&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>policy/v1&lt;/td>
&lt;td>PodDisruptionBudget&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>scheduling.k8s.io/v1&lt;/td>
&lt;td>PriorityClass&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>storage.k8s.io/v1&lt;/td>
&lt;td>CSIDriver&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>storage.k8s.io/v1&lt;/td>
&lt;td>CSINode&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>storage.k8s.io/v1&lt;/td>
&lt;td>CSIStorageCapacity&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>storage.k8s.io/v1&lt;/td>
&lt;td>StorageClass&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>storage.k8s.io/v1&lt;/td>
&lt;td>VolumeAttachment&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>ConfigMap&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>Endpoints&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>PersistentVolume&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>PersistentVolumeClaim&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>Pod&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>PodTemplate&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>ReplicationController&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>Secret&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1&lt;/td>
&lt;td>Service&lt;/td>
&lt;td>true&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="control-objects">Control objects&lt;/h3>
&lt;p>These are the EdgePlacement objects, their associated
SinglePlacementSlice objects, and the objects that direct
customization and summarization.&lt;/p>
&lt;h2 id="mailbox-workspaces">Mailbox workspaces&lt;/h2>
&lt;p>The mailbox controller maintains one mailbox workspace for each
SyncTarget. A mailbox workspace acts as a workload source for TMC,
prescribing the workload to go to the corresponding edge pcluster and
holding the corresponding TMC Placement object.&lt;/p>
&lt;p>A mailbox workspace contains the following items.&lt;/p>
&lt;ol>
&lt;li>APIBindings (maintained by the mailbox controller) to APIExports of
workload object types.&lt;/li>
&lt;li>Workload namespaces holding workload objects, post customization.&lt;/li>
&lt;li>A TMC Placement object.&lt;/li>
&lt;/ol>
&lt;h2 id="edge-cluster">Edge cluster&lt;/h2>
&lt;p>Also called edge pcluster.&lt;/p>
&lt;p>One of these contains the following items. FYI, these are the things
in the YAML output by &lt;code>kubectl kcp workload sync&lt;/code>. The responsibility
for creating and maintaining these objects is part of the problem of
bootstrapping the workload management layer and is not among the
things that this PoC takes a position on.&lt;/p>
&lt;ul>
&lt;li>A namespace that holds the syncer and associated objects.&lt;/li>
&lt;li>A ServiceAccount that the syncer authenticates as when accessing the
views of the center and when accessing the edge cluster.&lt;/li>
&lt;li>A Secret holding that ServiceAccount&amp;rsquo;s authorization token.&lt;/li>
&lt;li>A ClusterRole listing the non-namespaced privileges that the
syncer will use in the edge cluster.&lt;/li>
&lt;li>A ClusterRoleBinding linking the syncer&amp;rsquo;s ServiceAccount and ClusterRole.&lt;/li>
&lt;li>A Role listing the namespaced privileges that the syncer will use in
the edge cluster.&lt;/li>
&lt;li>A RoleBinding linking the syncer&amp;rsquo;s ServiceAccount and Role.&lt;/li>
&lt;li>A Secret holding the kubeconfig that the syncer will use to access
the edge cluster.&lt;/li>
&lt;li>A Deployment of the syncer.&lt;/li>
&lt;/ul>
&lt;h2 id="mailbox-controller">Mailbox Controller&lt;/h2>
&lt;p>This controller maintains one mailbox workspace per SyncTarget. Each
of these mailbox workspaces is used for a distinct TMC problem (e.g.,
Placement object). These workspaces are all children of the edge
service provider workspace.&lt;/p>
&lt;h2 id="edge-scheduler">Edge Scheduler&lt;/h2>
&lt;p>This controller monitors the EdgePlacement, Location, and SyncTarget
objects and maintains the results of matching. For each EdgePlacement
object this controller maintains an associated collection of
SinglePlacementSlice objects holding the matches for that
EdgePlacement. These SinglePlacementSlice objects appear in the same
workspace as the corresponding EdgePlacement; the remainder of how
they are linked is TBD.&lt;/p>
&lt;h2 id="placement-translator">Placement Translator&lt;/h2>
&lt;p>This controller translates each EdgePlacement object into a collection
of TMC Placement objects and corresponding related objects. For each
matching SinglePlacement, the placement translator maintains a TMC
Placement object and copy of the workload &amp;mdash; customized as directed.
Note that this involves sequencing constraints: CRDs and namespaces
have to be created before anything that uses them, and deleted after
everything that uses them. Note also that everything that has to be
denatured in the workload management workspace also has to be
denatured in the mailbox workspace.&lt;/p>
&lt;p>The job of the placement translator can be broken down into the
following four parts.&lt;/p>
&lt;ul>
&lt;li>Resolve each EdgePlacement&amp;rsquo;s &amp;ldquo;what&amp;rdquo; part to a list of particular
workspace items (namespaces and non-namespaced objects).&lt;/li>
&lt;li>Maintain the association between the resolved &amp;ldquo;where&amp;rdquo; from the edge
scheduler and the resolved what.&lt;/li>
&lt;li>Maintain the copies, with customization, of the workload objects
from source workspace to mailbox workspaces.&lt;/li>
&lt;li>Maintain the TMC Placement objects that derive from the
EdgePlacement objects.&lt;/li>
&lt;/ul>
&lt;h2 id="syncers">Syncers&lt;/h2>
&lt;p>This design nominally uses TMC and its syncers, but that can not be
exactly true because these syncers need to translate between denatured
objects in the mailbox workspace and natured objects in the edge
cluster. Or perhaps not, if there is an additional controller in the
edge cluster that handles the denatured-natured relation.&lt;/p>
&lt;h2 id="status-summarizer">Status Summarizer&lt;/h2>
&lt;p>For each EdgePlacement object and related objects this controller
maintains the directed status summary objects.&lt;/p>
&lt;h2 id="usage-scenario">Usage Scenario&lt;/h2>
&lt;p>The usage scenario breaks, at the highest level, into two parts:
inventory and workload.&lt;/p>
&lt;h3 id="inventory-usage">Inventory Usage&lt;/h3>
&lt;p>A user with infrastructure authority creates one or more inventory
management workspaces. Each such workspace needs to have the
following items, which that user will create if they are not
pre-populated by the workspace type.&lt;/p>
&lt;ul>
&lt;li>An APIBinding to the &lt;code>workload.kcp.io&lt;/code> APIExport to get
&lt;code>SyncTarget&lt;/code>.&lt;/li>
&lt;li>An APIBinding to the &lt;code>scheduling.kcp.io&lt;/code> APIExport to get
&lt;code>Location&lt;/code>.&lt;/li>
&lt;li>A ServiceAccount (with associated token-bearing Secret) (details
TBD) that the mailbox controller authenticates as.&lt;/li>
&lt;li>A ClusterRole and ClusterRoleBinding that authorize said
ServiceAccount to do what the mailbox controller needs to do.&lt;/li>
&lt;/ul>
&lt;p>This user also creates one or more edge clusters.&lt;/p>
&lt;p>For each of those edge clusters, this user creates the following.&lt;/p>
&lt;ul>
&lt;li>a corresponding SyncTarget, with an annotation referring to the
following Secret object, in one of those inventory management
workspaces;&lt;/li>
&lt;li>a Secret, in the same workspace, holding a kubeconfig that the
central automation will use to install the syncer in the edge
cluster;&lt;/li>
&lt;li>a Location, in the same workspace, that matches only that
SyncTarget.&lt;/li>
&lt;/ul>
&lt;h3 id="workload-usage">Workload usage&lt;/h3>
&lt;p>A user with workload authority starts by creating one or more workload
management workspaces. Each needs to have the following, which that
user creates if the workload type did not already provide.&lt;/p>
&lt;ul>
&lt;li>An APIBinding to the APIExport of &lt;code>edge.kcp.io&lt;/code> from the edge
service provider workspace.&lt;/li>
&lt;li>For each of the Edge Scheduler, the Placement Translator, and the
Status Summarizer:
&lt;ul>
&lt;li>A ServiceAccount for that controller to authenticate as;&lt;/li>
&lt;li>A ClusterRole granting the privileges needed by that controller;&lt;/li>
&lt;li>A ClusterRoleBinding that binds those two.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>This user also uses the edge-workspace-as-container view of each such
workspace to describe the workload desired state.&lt;/p>
&lt;p>This user creates one or more EdgePlacement objects to say which
workload goes where. These may be accompanied by API objects that
specify rule-baesd customization, specify how status is to be
summarized.&lt;/p>
&lt;p>The edge-mc implementation propagates the desired state from center to
edge and collects the specified information from edge to center.&lt;/p>
&lt;p>The edge user monitors status summary objects in their workload
management workspaces.&lt;/p>
&lt;p>The status summaries may include limited-length lists of broken
objects.&lt;/p>
&lt;p>Full status from the edge is available in the mailbox workspaces.&lt;/p></description></item><item><title>Docs: Invitation</title><link>https://docs.kcp-edge.io/docs/coding-milestones/poc2023q1/coding-milestone-invite-q1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.kcp-edge.io/docs/coding-milestones/poc2023q1/coding-milestone-invite-q1/</guid><description>
&lt;p>Dear Contributors,&lt;/p>
&lt;p>We are excited to invite you to join the first &lt;a href="https://github.com/kcp-dev/edge-mc">KCP-Edge opensource community&lt;/a> coding sprint. We will be focus on several key projects that are critical to the development of state-based edge solutions. Our collective work will be showcased to the opensource community on Thursday, March 30th.&lt;/p>
&lt;p>This coding sprint will provide a great opportunity for you to showcase your skills, learn new techniques, and collaborate with other experienced engineers in the KCP-Edge community. We believe that your contributions will be invaluable in helping us achieve our goals and making a lasting impact in the field of state-based edge technology.&lt;/p>
&lt;p>The coding sprint will be dedicated to completing the following workload management elements:&lt;/p>
&lt;ul>
&lt;li>Implementing an edge scheduler and placement translator, including customization options,&lt;/li>
&lt;li>Incorporating existing customization API into the &lt;a href="https://github.com/kcp-dev/edge-mc">KCP-Edge repo&lt;/a>,&lt;/li>
&lt;li>Investigating implementation of a status summarizer, starting with basic implicit status, and later adding programmed summarization,&lt;/li>
&lt;li>Updating summarization API and integrating it into the &lt;a href="https://github.com/kcp-dev/edge-mc">KCP-Edge repo&lt;/a>,&lt;/li>
&lt;li>Streamlining the creation of workload management workspaces,&lt;/li>
&lt;li>Completing our existing implementation of a mailbox controller,&lt;/li>
&lt;li>Examining the use of Postgresql through Kine instead of etcd for scalability,&lt;/li>
&lt;li>Revising the milestone outline with regards to defining bootstrapping and support for cluster-scoped resources.&lt;/li>
&lt;/ul>
&lt;p>In addition to workload management, we will also be working on inventory management for the demo, as well as designing various demo scenarios, including a baseline demo with kubectl, demos with ArgoCD, FluxCD, and the European Space Agency (ESA). To support the engineers and demonstrations we will also need to automate the process of creating infrastructure, deploying demo pieces and instrumentation, bootstrapping, running scenarios, and collecting data.&lt;/p>
&lt;p>If you are interested in joining us for this exciting coding sprint, please slack me &lt;a href="https://kubernetes.slack.com/team/U0462LN24QJ">@Andy Anderson&lt;/a> so I can connect you with others in your area of interest. There is a place for every skillset to contribute. Not quite sure? You can join our &lt;a href="https://calendar.google.com/calendar/embed?src=ujjomvk4fa9fgdaem32afgl7g0%40group.calendar.google.com">bi-weekly community meetings&lt;/a> to watch our progress.&lt;/p></description></item></channel></rss>